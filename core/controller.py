# -*- coding: utf-8 -*-
"""
ë©”ì¸ ì»¨íŠ¸ë¡¤ëŸ¬ - ì—‘ì…€ ì·¨í•© í”„ë¡œì„¸ìŠ¤ ì „ì²´ ì œì–´
"""

import os
import pandas as pd
from typing import List, Dict, Any, Optional, Callable
from pathlib import Path
from datetime import datetime
import threading
import time

from .processor import ExcelProcessor, FileStructure
from .normalizer import DataNormalizer
import config

class MergeController:
    """ì—‘ì…€ ë³‘í•© ì»¨íŠ¸ë¡¤ëŸ¬"""
    
    def __init__(self):
        """ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™”"""
        self.processor = ExcelProcessor()
        self.normalizer = DataNormalizer()
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_processing = False
        self.is_cancelled = False
        self.current_progress = 0.0
        self.current_status = "ì¤€ë¹„ ì¤‘"
        
        # UI ì°¸ì¡°
        self.ui = None
        
        # ì²˜ë¦¬ ê²°ê³¼
        self.merge_result = None
        self.change_logs = []
        self.validation_passed = False  # ê²€ìˆ˜ í†µê³¼ ì—¬ë¶€
        
    def set_ui(self, ui):
        """UI ì°¸ì¡° ì„¤ì •"""
        self.ui = ui
        
    def cleanup(self):
        """ì •ë¦¬ ì‘ì—…"""
        self.is_cancelled = True
        
    def start_merge(self, reference_file: str, merge_files: List[str], output_file: str = None) -> bool:
        """
        ë³‘í•© í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (ë¹„ë™ê¸°)
        
        Args:
            reference_file: ì›ë³¸ íŒŒì¼ ê²½ë¡œ
            merge_files: ì·¨í•©í•  íŒŒì¼ ëª©ë¡
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
            
        Returns:
            bool: ì‹œì‘ ì„±ê³µ ì—¬ë¶€
        """
        if self.is_processing:
            self._show_error("ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.")
            return False
        
        # ì…ë ¥ íŒŒì¼ ê²€ì¦
        if not reference_file or not merge_files:
            self._show_error("ì›ë³¸ íŒŒì¼ê³¼ ì·¨í•© íŒŒì¼ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return False
        
        # ì¶œë ¥ íŒŒì¼ëª… ì²˜ë¦¬
        if not output_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"í†µí•©_ë°ì´í„°_{timestamp}.xlsx"
        
        print(f"ğŸš€ ì·¨í•© í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        print(f"ğŸ“ ì›ë³¸ íŒŒì¼: {Path(reference_file).name}")
        print(f"ğŸ“Š ì·¨í•© íŒŒì¼: {len(merge_files)}ê°œ")
        for i, file in enumerate(merge_files, 1):
            print(f"   {i}. {Path(file).name}")
        print(f"ğŸ’¾ ì¶œë ¥ íŒŒì¼: {output_file}")
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(reference_file):
            self._show_error(f"ì›ë³¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {reference_file}")
            return False
        
        for merge_file in merge_files:
            if not os.path.exists(merge_file):
                self._show_error(f"ì·¨í•© íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {merge_file}")
                return False
        
        # UI ìƒíƒœ ì—…ë°ì´íŠ¸
        if self.ui:
            self.ui.set_merge_state(True)
            self.ui.update_progress(0, "ì·¨í•© ì‹œì‘...")
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        thread = threading.Thread(
            target=self._merge_process,
            args=(reference_file, merge_files, output_file)
        )
        thread.daemon = True
        thread.start()
        
        print(f"âœ… ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")
        return True
    
    def cancel_merge(self):
        """ë³‘í•© í”„ë¡œì„¸ìŠ¤ ì·¨ì†Œ"""
        self.is_cancelled = True
        self._update_status("ì·¨ì†Œ ì¤‘...")
        print("â¹ï¸ ì‚¬ìš©ìê°€ ì·¨í•©ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
    
    def get_progress(self) -> float:
        """í˜„ì¬ ì§„í–‰ë¥  ë°˜í™˜"""
        return self.current_progress
    
    def get_status(self) -> str:
        """í˜„ì¬ ìƒíƒœ ë°˜í™˜"""
        return self.current_status
    
    def is_validation_passed(self) -> bool:
        """ê²€ìˆ˜ í†µê³¼ ì—¬ë¶€ ë°˜í™˜"""
        return self.validation_passed
    
    def _merge_process(self, reference_file: str, merge_files: List[str], output_file: str):
        """
        ì‹¤ì œ ë³‘í•© ì²˜ë¦¬ ë¡œì§
        
        Args:
            reference_file: ì›ë³¸ íŒŒì¼ ê²½ë¡œ
            merge_files: ì·¨í•©í•  íŒŒì¼ ëª©ë¡
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        print(f"ğŸ”„ _merge_process ì‹œì‘ë¨")
        print(f"ğŸ“ reference_file: {reference_file}")
        print(f"ğŸ“Š merge_files: {merge_files}")
        print(f"ğŸ’¾ output_file: {output_file}")
        
        try:
            self.is_processing = True
            self.is_cancelled = False
            self.current_progress = 0.0
            self.validation_passed = False
            
            print(f"ğŸ—ï¸ ì²˜ë¦¬ ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ")
            
            total_steps = 6 + len(merge_files)  # ë¶„ì„, ê²€ìˆ˜, ì„œì‹ì¶”ì¶œ, ë³‘í•©ì²˜ë¦¬, ë°ì´í„°ê²€ì¦, ì €ì¥ + ê° íŒŒì¼ ì²˜ë¦¬
            current_step = 0
            
            print(f"ğŸ“‹ ì´ ë‹¨ê³„: {total_steps}ê°œ")
            
            # 1. ì›ë³¸ íŒŒì¼ ë¶„ì„
            self._update_progress(current_step / total_steps, "ì›ë³¸ íŒŒì¼ ë¶„ì„ ì¤‘...")
            
            reference_structure = self.processor.read_file_structure(reference_file)
            if reference_structure.error_message:
                raise Exception(f"ì›ë³¸ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {reference_structure.error_message}")
            
            if not reference_structure.sheets:
                raise Exception("ì›ë³¸ íŒŒì¼ì— ìœ íš¨í•œ ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì›ë³¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì¤‘ìš”!)
            reference_structure.file_path = reference_file
            
            current_step += 1
            
            if self.is_cancelled:
                self._handle_cancellation()
                return
                
            # 2. ì‚¬ì „ ê²€ìˆ˜ - íŒŒì¼ í˜¸í™˜ì„± í™•ì¸
            self._update_progress(current_step / total_steps, "íŒŒì¼ í˜¸í™˜ì„± ê²€ìˆ˜ ì¤‘...")
            
            validation_result = self._validate_files_compatibility(reference_file, merge_files)
            if not validation_result['success']:
                raise Exception(f"íŒŒì¼ í˜¸í™˜ì„± ê²€ìˆ˜ ì‹¤íŒ¨: {validation_result['message']}")
            
            current_step += 1
            
            if self.is_cancelled:
                self._handle_cancellation()
                return
            
            # 3. ì„œì‹ ê¸°ì¤€ ì¶”ì¶œ
            self._update_progress(current_step / total_steps, "ì„œì‹ ê¸°ì¤€ ì¶”ì¶œ ì¤‘...")
            
            format_standards = self._extract_format_standards(reference_structure)
            
            current_step += 1
            
            if self.is_cancelled:
                self._handle_cancellation()
                return
            
            # 4. ê° ì·¨í•© íŒŒì¼ ì²˜ë¦¬
            merged_data = {}  # {sheet_name: [dataframes]}
            processing_errors = []
            
            for i, merge_file in enumerate(merge_files):
                self._update_progress(
                    current_step / total_steps, 
                    f"íŒŒì¼ ì²˜ë¦¬ ì¤‘... ({i+1}/{len(merge_files)}) {Path(merge_file).name}"
                )
                
                try:
                    file_data = self._process_merge_file(
                        merge_file, reference_structure, format_standards
                    )
                    
                    # ë°ì´í„° ë³‘í•©
                    for sheet_name, df in file_data.items():
                        if sheet_name not in merged_data:
                            merged_data[sheet_name] = []
                        merged_data[sheet_name].append(df)
                        
                except Exception as e:
                    error_msg = f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({Path(merge_file).name}): {str(e)}"
                    processing_errors.append(error_msg)
                    self._log_error(error_msg)
                
                current_step += 1
                
                if self.is_cancelled:
                    self._handle_cancellation()
                    return
            
            # 5. ë°ì´í„° í†µí•©
            self._update_progress(current_step / total_steps, "ë°ì´í„° í†µí•© ì¤‘...")
            
            combined_data = self._combine_sheet_data(merged_data, reference_structure)
            
            current_step += 1
            
            if self.is_cancelled:
                self._handle_cancellation()
                return
                
            # 6. ë°ì´í„° í’ˆì§ˆ ê²€ì¦
            self._update_progress(current_step / total_steps, "ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì¤‘...")
            
            validation_result = self._validate_merged_data(combined_data, reference_structure)
            if not validation_result['success']:
                self._log_error(f"ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ê²½ê³ : {validation_result['message']}")
            else:
                self.validation_passed = True
                print("âœ… ë°ì´í„° í’ˆì§ˆ ê²€ì¦ í†µê³¼")
            
            current_step += 1
            
            if self.is_cancelled:
                self._handle_cancellation()
                return
            
            # 7. ê²°ê³¼ íŒŒì¼ ì €ì¥
            self._update_progress(current_step / total_steps, "ê²°ê³¼ íŒŒì¼ ì €ì¥ ì¤‘...")
            
            self._save_merged_file(combined_data, output_file, reference_structure)
            
            # ì™„ë£Œ
            self._update_progress(1.0, "ì²˜ë¦¬ ì™„ë£Œ!")
            
            # ìµœì¢… ìƒíƒœ ë©”ì‹œì§€
            success_files = len(merge_files) - len(processing_errors)
            status_msg = f"ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ! ({success_files}/{len(merge_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ë¨)"
            
            if processing_errors:
                status_msg += f" - {len(processing_errors)}ê°œ íŒŒì¼ì—ì„œ ì˜¤ë¥˜ ë°œìƒ"
            
            self._update_status(status_msg)
            
            # ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±
            self._create_completion_report(success_files, combined_data, processing_errors)
            
            # ê²€ìˆ˜ í†µê³¼ ì—¬ë¶€ì— ë”°ë¥¸ ë©”ì‹œì§€
            if self.validation_passed:
                self._show_success(f"âœ… ì·¨í•©ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n" + 
                                 f"ğŸ“Š ê²€ìˆ˜ í†µê³¼: ë°ì´í„° í’ˆì§ˆì´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.\n" +
                                 f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_file}")
            else:
                self._show_success(f"âš ï¸ ì·¨í•©ì´ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ì¼ë¶€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\n" + 
                                 f"ğŸ“‹ ì²˜ë¦¬ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n" +
                                 f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_file}")
            
        except Exception as e:
            self._handle_error(str(e))
        finally:
            self.is_processing = False
            if self.ui:
                self.ui.set_merge_state(False)
    
    def _validate_files_compatibility(self, reference_file: str, merge_files: List[str]) -> Dict[str, Any]:
        """
        íŒŒì¼ í˜¸í™˜ì„± ì‚¬ì „ ê²€ìˆ˜
        
        Args:
            reference_file: ì›ë³¸ íŒŒì¼
            merge_files: ì·¨í•©í•  íŒŒì¼ë“¤
            
        Returns:
            Dict: ê²€ìˆ˜ ê²°ê³¼
        """
        try:
            print("ğŸ” íŒŒì¼ í˜¸í™˜ì„± ê²€ìˆ˜ ì‹œì‘...")
            
            # ì›ë³¸ íŒŒì¼ êµ¬ì¡° ë¶„ì„
            ref_structure = self.processor.read_file_structure(reference_file)
            if ref_structure.error_message:
                return {
                    'success': False, 
                    'message': f"ì›ë³¸ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {ref_structure.error_message}"
                }
            
            ref_sheet_names = [sheet.name for sheet in ref_structure.sheets]
            compatibility_issues = []
            
            # ê° ì·¨í•© íŒŒì¼ ê²€ìˆ˜
            for i, merge_file in enumerate(merge_files, 1):
                try:
                    file_structure = self.processor.read_file_structure(merge_file)
                    if file_structure.error_message:
                        compatibility_issues.append(f"íŒŒì¼ {i} ({Path(merge_file).name}): êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨")
                        continue
                    
                    # ì‹œíŠ¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                    merge_sheet_names = [sheet.name for sheet in file_structure.sheets]
                    sheet_mappings = self.processor.match_sheets(ref_sheet_names, merge_sheet_names)
                    
                    if not sheet_mappings:
                        compatibility_issues.append(f"íŒŒì¼ {i} ({Path(merge_file).name}): ë§¤ì¹­ë˜ëŠ” ì‹œíŠ¸ê°€ ì—†ìŒ")
                    
                except Exception as e:
                    compatibility_issues.append(f"íŒŒì¼ {i} ({Path(merge_file).name}): ê²€ìˆ˜ ì¤‘ ì˜¤ë¥˜ - {str(e)}")
            
            # ê²°ê³¼ íŒì •
            if compatibility_issues:
                issues_text = "\n".join([f"  - {issue}" for issue in compatibility_issues[:5]])  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                if len(compatibility_issues) > 5:
                    issues_text += f"\n  - ... ë° {len(compatibility_issues) - 5}ê°œ ì¶”ê°€ ë¬¸ì œ"
                
                return {
                    'success': False,
                    'message': f"í˜¸í™˜ì„± ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:\n{issues_text}",
                    'issues': compatibility_issues
                }
            
            print(f"âœ… ëª¨ë“  íŒŒì¼ì´ í˜¸í™˜ì„± ê²€ìˆ˜ë¥¼ í†µê³¼í–ˆìŠµë‹ˆë‹¤.")
            return {'success': True, 'message': 'í˜¸í™˜ì„± ê²€ìˆ˜ í†µê³¼'}
            
        except Exception as e:
            return {
                'success': False,
                'message': f"ê²€ìˆ˜ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
            }
    
    def _validate_merged_data(self, combined_data: Dict[str, pd.DataFrame], 
                             reference_structure: FileStructure) -> Dict[str, Any]:
        """
        ë³‘í•©ëœ ë°ì´í„°ì˜ í’ˆì§ˆ ê²€ì¦
        
        Args:
            combined_data: ë³‘í•©ëœ ë°ì´í„°
            reference_structure: ì›ë³¸ íŒŒì¼ êµ¬ì¡°
            
        Returns:
            Dict: ê²€ì¦ ê²°ê³¼
        """
        try:
            print("ğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œì‘...")
            
            validation_issues = []
            
            for sheet in reference_structure.sheets:
                sheet_name = sheet.name
                
                if sheet_name not in combined_data:
                    validation_issues.append(f"ì‹œíŠ¸ '{sheet_name}'ì´ ê²°ê³¼ì— í¬í•¨ë˜ì§€ ì•ŠìŒ")
                    continue
                
                df = combined_data[sheet_name]
                
                # ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                if df.empty:
                    validation_issues.append(f"ì‹œíŠ¸ '{sheet_name}'ì— ë°ì´í„°ê°€ ì—†ìŒ")
                    continue
                
                # í•„ìˆ˜ ì—´ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                missing_columns = set(sheet.columns) - set(df.columns)
                if missing_columns:
                    validation_issues.append(f"ì‹œíŠ¸ '{sheet_name}'ì—ì„œ ëˆ„ë½ëœ ì—´: {', '.join(missing_columns)}")
                
                # ë°ì´í„° í–‰ ìˆ˜ í™•ì¸
                if len(df) == 0:
                    validation_issues.append(f"ì‹œíŠ¸ '{sheet_name}'ì— ë°ì´í„° í–‰ì´ ì—†ìŒ")
                
                # ì¤‘ë³µ ë°ì´í„° í™•ì¸ (ê°„ë‹¨í•œ ì²´í¬)
                if len(df) != len(df.drop_duplicates()):
                    duplicate_count = len(df) - len(df.drop_duplicates())
                    validation_issues.append(f"ì‹œíŠ¸ '{sheet_name}'ì—ì„œ {duplicate_count}ê°œì˜ ì¤‘ë³µ í–‰ ë°œê²¬")
            
            # ê²°ê³¼ íŒì •
            if validation_issues:
                issues_text = "\n".join([f"  - {issue}" for issue in validation_issues[:5]])
                if len(validation_issues) > 5:
                    issues_text += f"\n  - ... ë° {len(validation_issues) - 5}ê°œ ì¶”ê°€ ë¬¸ì œ"
                
                return {
                    'success': False,
                    'message': f"ë°ì´í„° í’ˆì§ˆ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:\n{issues_text}",
                    'issues': validation_issues
                }
            
            print(f"âœ… ë°ì´í„° í’ˆì§ˆ ê²€ì¦ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤.")
            return {'success': True, 'message': 'ë°ì´í„° í’ˆì§ˆ ê²€ì¦ í†µê³¼'}
            
        except Exception as e:
            return {
                'success': False,
                'message': f"ê²€ì¦ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
            }
    
    def _extract_format_standards(self, reference_structure: FileStructure) -> Dict[str, Dict[str, Dict[str, Any]]]:
        """
        ì›ë³¸ íŒŒì¼ë¡œë¶€í„° ì„œì‹ ê¸°ì¤€ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)
        
        Args:
            reference_structure: ì›ë³¸ íŒŒì¼ êµ¬ì¡°
            
        Returns:
            Dict: ì‹œíŠ¸ë³„ ì„œì‹ ê¸°ì¤€ ì •ë³´
        """
        format_standards = {}
        
        for sheet in reference_structure.sheets:
            sheet_name = sheet.name
            
            # ì‹¤ì œ ë°ì´í„°ë¥¼ ì½ì–´ì„œ ì„œì‹ ê¸°ì¤€ ì¶”ì¶œ
            try:
                df = self.processor.read_sheet_data(reference_structure.file_path, sheet_name)
                
                # ì •ê·œí™”ê¸°ë¥¼ ì‚¬ìš©í•´ì„œ ì‹¤ì œ ì„œì‹ ê¸°ì¤€ ì¶”ì¶œ
                detailed_standards = self.normalizer.extract_format_standards(df, sheet.data_types)
                
                format_standards[sheet_name] = detailed_standards
                
                print(f"ğŸ“‹ {sheet_name} ì„œì‹ ê¸°ì¤€:")
                for col_name, standard in detailed_standards.items():
                    print(f"  {col_name}: {standard}")
                
            except Exception as e:
                print(f"âš ï¸ {sheet_name} ì„œì‹ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                # ê¸°ë³¸ ì„œì‹ìœ¼ë¡œ ëŒ€ì²´
                format_standards[sheet_name] = {
                    col: {'type': sheet.data_types.get(col, 'text')} 
                    for col in sheet.columns
                }
        
        return format_standards
    
    def _process_merge_file(self, merge_file: str, reference_structure: FileStructure, 
                           format_standards: Dict[str, Dict[str, Dict[str, Any]]]) -> Dict[str, pd.DataFrame]:
        """
        ê°œë³„ ì·¨í•© íŒŒì¼ ì²˜ë¦¬ (ë¡œê·¸ ì¶”ê°€)
        
        Args:
            merge_file: ì·¨í•©í•  íŒŒì¼ ê²½ë¡œ
            reference_structure: ì›ë³¸ íŒŒì¼ êµ¬ì¡°
            format_standards: ì„œì‹ ê¸°ì¤€
            
        Returns:
            Dict[str, pd.DataFrame]: ì‹œíŠ¸ë³„ ì²˜ë¦¬ëœ ë°ì´í„°
        """
        result_data = {}
        file_name = Path(merge_file).name
        
        try:
            # íŒŒì¼ êµ¬ì¡° ë¶„ì„
            file_structure = self.processor.read_file_structure(merge_file)
            
            if file_structure.error_message:
                raise Exception(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {file_structure.error_message}")
            
            # ì‹œíŠ¸ ë§¤ì¹­
            reference_sheet_names = [sheet.name for sheet in reference_structure.sheets]
            target_sheet_names = [sheet.name for sheet in file_structure.sheets]
            
            sheet_mappings = self.processor.match_sheets(reference_sheet_names, target_sheet_names)
            
            # ì‹œíŠ¸ ë§¤ì¹­ ë¡œê·¸ ê¸°ë¡
            for ref_sheet, target_sheet in sheet_mappings.items():
                if ref_sheet != target_sheet:
                    # ì‹œíŠ¸ëª…ì´ ë‹¤ë¥¼ ë•Œë§Œ ë¡œê·¸ ê¸°ë¡
                    self.normalizer._log_change_dict(
                        file_name, ref_sheet, -1, 'SHEET_NAME',
                        'sheet_mapping', target_sheet, ref_sheet
                    )
            
            # ê° ì‹œíŠ¸ ì²˜ë¦¬
            for ref_sheet_name, target_sheet_name in sheet_mappings.items():
                # ì°¸ì¡° ì‹œíŠ¸ ì •ë³´
                ref_sheet = next((s for s in reference_structure.sheets if s.name == ref_sheet_name), None)
                if not ref_sheet:
                    continue
                
                # ë°ì´í„° ì½ê¸°
                df = self.processor.read_sheet_data(merge_file, target_sheet_name, chunk_size=None)
                
                if df.empty:
                    continue
                
                # ì—´ ë§¤ì¹­ ë° ì •ë ¬
                column_mappings = self.processor.match_columns(ref_sheet.columns, df.columns.tolist())
                
                # ì—´ ë§¤ì¹­ ë¡œê·¸ ê¸°ë¡
                for ref_col, target_col in column_mappings.items():
                    if ref_col != target_col:
                        # ì—´ëª…ì´ ë‹¤ë¥¼ ë•Œë§Œ ë¡œê·¸ ê¸°ë¡
                        self.normalizer._log_change_dict(
                            file_name, ref_sheet_name, -1, ref_col,
                            'column_mapping', target_col, ref_col
                        )
                
                aligned_df = self._align_columns(df, ref_sheet.columns, column_mappings)
                
                # ë°ì´í„° ì •ê·œí™”
                normalized_df, change_log = self.normalizer.normalize_data(
                    aligned_df, format_standards[ref_sheet_name], file_name, ref_sheet_name
                )
                
                # ì •ê·œí™” ê²°ê³¼ í™•ì¸ ë¡œê·¸
                print(f"ğŸ”§ ì •ê·œí™” ì™„ë£Œ: {file_name} -> {len(change_log)}ê°œ ë³€ê²½ì‚¬í•­")
                
                # íŒŒì¼ëª… ì •ë³´ë¥¼ ê° í–‰ì˜ ë¹„ê³ ì— ì¶”ê°€í•˜ê¸° ìœ„í•´ ë©”íƒ€ë°ì´í„° ì €ì¥
                normalized_df['_source_file'] = file_name  # ì„ì‹œ ì»¬ëŸ¼
                
                result_data[ref_sheet_name] = normalized_df
        
        except Exception as e:
            raise Exception(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({Path(merge_file).name}): {str(e)}")
        
        return result_data
    
    def _align_columns(self, df: pd.DataFrame, reference_columns: List[str], 
                      column_mappings: Dict[str, str]) -> pd.DataFrame:
        """
        ì—´ ìˆœì„œë¥¼ ì›ë³¸ê³¼ ì¼ì¹˜í•˜ë„ë¡ ì •ë ¬
        
        Args:
            df: ì…ë ¥ ë°ì´í„°í”„ë ˆì„
            reference_columns: ì›ë³¸ ì—´ ìˆœì„œ
            column_mappings: ì—´ ë§¤í•‘ ì •ë³´
            
        Returns:
            pd.DataFrame: ì •ë ¬ëœ ë°ì´í„°í”„ë ˆì„
        """
        aligned_df = pd.DataFrame()
        
        for ref_col in reference_columns:
            if ref_col in column_mappings:
                # ë§¤í•‘ëœ ì—´ì´ ìˆëŠ” ê²½ìš°
                source_col = column_mappings[ref_col]
                if source_col in df.columns:
                    aligned_df[ref_col] = df[source_col]
                else:
                    aligned_df[ref_col] = None
            else:
                # ë§¤í•‘ëœ ì—´ì´ ì—†ëŠ” ê²½ìš° ë¹ˆ ì—´ ì¶”ê°€
                aligned_df[ref_col] = None
        
        return aligned_df
    
    def _combine_sheet_data(self, merged_data: Dict[str, List[pd.DataFrame]], 
                           reference_structure: FileStructure) -> Dict[str, pd.DataFrame]:
        """
        ì‹œíŠ¸ë³„ ë°ì´í„° ê²°í•© (ë¹„ê³  ì»¬ëŸ¼ ì¶”ê°€)
        
        Args:
            merged_data: ì‹œíŠ¸ë³„ ë°ì´í„°í”„ë ˆì„ ëª©ë¡
            reference_structure: ì›ë³¸ íŒŒì¼ êµ¬ì¡°
            
        Returns:
            Dict[str, pd.DataFrame]: ê²°í•©ëœ ì‹œíŠ¸ë³„ ë°ì´í„°
        """
        combined_data = {}
        
        for sheet in reference_structure.sheets:
            sheet_name = sheet.name
            
            if sheet_name not in merged_data:
                # ì›ë³¸ ë°ì´í„°ë§Œ ìˆëŠ” ê²½ìš°
                original_df = self.processor.read_sheet_data(
                    reference_structure.file_path, sheet_name
                )
                # ë¹„ê³  ì»¬ëŸ¼ ì¶”ê°€
                original_df['ë¹„ê³ '] = ''
                combined_data[sheet_name] = original_df
            else:
                # ì›ë³¸ + ì·¨í•© ë°ì´í„°
                dataframes = merged_data[sheet_name]
                
                # ì›ë³¸ ë°ì´í„° ì¶”ê°€
                original_df = self.processor.read_sheet_data(
                    reference_structure.file_path, sheet_name
                )
                # ì›ë³¸ ë°ì´í„°ì— ë¹„ê³  ì»¬ëŸ¼ ì¶”ê°€
                original_df['ë¹„ê³ '] = ''
                dataframes.insert(0, original_df)
                
                # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ì— ë¹„ê³  ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì¶”ê°€
                for i, df in enumerate(dataframes):
                    if 'ë¹„ê³ ' not in df.columns:
                        df['ë¹„ê³ '] = ''
                
                # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ê²°í•©
                combined_df = pd.concat(dataframes, ignore_index=True)
                
                # ë³€ê²½ ë¡œê·¸ë¥¼ ë¹„ê³ ì— ë°˜ì˜
                combined_df = self._add_change_notes_to_dataframe(combined_df, sheet_name)
                
                combined_data[sheet_name] = combined_df
        
        return combined_data
    
    def _add_change_notes_to_dataframe(self, df: pd.DataFrame, sheet_name: str) -> pd.DataFrame:
        """
        ë°ì´í„°í”„ë ˆì„ì— ë³€ê²½ ì‚¬í•­ì„ ë¹„ê³ ë¡œ ì¶”ê°€ (ê°œì„ ëœ ë²„ì „)
        
        Args:
            df: ëŒ€ìƒ ë°ì´í„°í”„ë ˆì„
            sheet_name: ì‹œíŠ¸ëª…
            
        Returns:
            pd.DataFrame: ë¹„ê³ ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
        """
        # ì„ì‹œ ì»¬ëŸ¼ì—ì„œ íŒŒì¼ ì¶œì²˜ ì •ë³´ ì¶”ì¶œ
        if '_source_file' in df.columns:
            for idx, row in df.iterrows():
                source_file = row['_source_file']
                if pd.notna(source_file) and str(source_file).strip():
                    # ì›ë³¸ íŒŒì¼ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶œì²˜ ì •ë³´ ì¶”ê°€
                    if not source_file.startswith('ì›ë³¸'):
                        existing_note = str(df.iloc[idx]['ë¹„ê³ ']) if pd.notna(df.iloc[idx]['ë¹„ê³ ']) else ''
                        source_note = f"ì¶œì²˜:{source_file}"
                        
                        if existing_note:
                            new_note = f"{existing_note}; {source_note}"
                        else:
                            new_note = source_note
                        
                        df.iloc[idx, df.columns.get_loc('ë¹„ê³ ')] = new_note
            
            # ì„ì‹œ ì»¬ëŸ¼ ì œê±°
            df = df.drop(columns=['_source_file'])
        
        # ì •ê·œí™”ê¸°ì—ì„œ ìˆ˜ì§‘í•œ ë³€ê²½ ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°
        if hasattr(self.normalizer, 'change_logs'):
            change_logs = self.normalizer.change_logs
            
            # íŒŒì¼ë³„ë¡œ ë¡œê·¸ ê·¸ë£¹í™”
            file_logs = {}
            for log in change_logs:
                if log.get('sheet_name') == sheet_name:
                    file_name = log.get('file_name', '')
                    if file_name not in file_logs:
                        file_logs[file_name] = []
                    file_logs[file_name].append(log)
            
            # íŒŒì¼ë³„ë¡œ ë³€ê²½ ì‚¬í•­ ì²˜ë¦¬
            for file_name, logs in file_logs.items():
                # ì‹œíŠ¸ ë° ì—´ ë§¤í•‘ ì •ë³´ ìˆ˜ì§‘
                sheet_mappings = [log for log in logs if log.get('change_type') == 'sheet_mapping']
                column_mappings = [log for log in logs if log.get('change_type') == 'column_mapping']
                
                # í•´ë‹¹ íŒŒì¼ì˜ ëª¨ë“  í–‰ì— ë§¤í•‘ ì •ë³´ ì¶”ê°€
                if sheet_mappings or column_mappings:
                    for idx, row in df.iterrows():
                        if '_source_file' in df.columns and df.iloc[idx]['_source_file'] == file_name:
                            continue  # ì´ë¯¸ ì²˜ë¦¬ë¨
                        
                        # í•´ë‹¹ íŒŒì¼ì—ì„œ ì˜¨ ë°ì´í„°ì¸ì§€ í™•ì¸ (ê°„ì ‘ì ìœ¼ë¡œ)
                        existing_note = str(df.iloc[idx]['ë¹„ê³ ']) if pd.notna(df.iloc[idx]['ë¹„ê³ ']) else ''
                        if file_name in existing_note or (not existing_note and idx >= 3):  # ì›ë³¸ ë‹¤ìŒë¶€í„°
                            
                            mapping_notes = []
                            
                            # ì‹œíŠ¸ ë§¤í•‘ ì •ë³´
                            for log in sheet_mappings:
                                original = log.get('original_value', '')
                                mapped = log.get('new_value', '')
                                if original != mapped:
                                    mapping_notes.append(f"ì‹œíŠ¸ë§¤ì¹­({original}â†’{mapped})")
                            
                            # ì—´ ë§¤í•‘ ì •ë³´
                            for log in column_mappings:
                                original = log.get('original_value', '')
                                mapped = log.get('new_value', '')
                                column = log.get('column_name', '')
                                if original != mapped:
                                    mapping_notes.append(f"ì—´ë§¤ì¹­({column}:{original}â†’{mapped})")
                            
                            if mapping_notes:
                                mapping_text = "; ".join(mapping_notes)
                                if existing_note:
                                    new_note = f"{existing_note}; {mapping_text}"
                                else:
                                    new_note = mapping_text
                                
                                df.iloc[idx, df.columns.get_loc('ë¹„ê³ ')] = new_note
                
                # í–‰ë³„ ë³€ê²½ ì‚¬í•­ (ë‚ ì§œ í˜•ì‹ ë“±)
                row_changes = [log for log in logs if log.get('row_index', -1) >= 0]
                for log in row_changes:
                    row_idx = log.get('row_index', -1)
                    if 0 <= row_idx < len(df):
                        change_type = log.get('change_type', '')
                        column_name = log.get('column_name', '')
                        original_value = log.get('original_value', '')
                        new_value = log.get('new_value', '')
                        
                        # ë³€ê²½ ì‚¬í•­ í…ìŠ¤íŠ¸ ìƒì„±
                        if change_type == 'date_format':
                            note = f"ë‚ ì§œí˜•ì‹ë³€ê²½({column_name}:{original_value}â†’{new_value})"
                        elif change_type == 'number_format':
                            note = f"ìˆ«ìí˜•ì‹ë³€ê²½({column_name}:{original_value}â†’{new_value})"
                        elif change_type == 'text_format':
                            note = f"í…ìŠ¤íŠ¸ì •ë¦¬({column_name}:{original_value}â†’{new_value})"
                        else:
                            note = f"{change_type}({column_name}:{original_value}â†’{new_value})"
                        
                        # ê¸°ì¡´ ë¹„ê³ ì— ì¶”ê°€
                        existing_note = str(df.iloc[row_idx]['ë¹„ê³ ']) if pd.notna(df.iloc[row_idx]['ë¹„ê³ ']) else ''
                        if existing_note:
                            new_note = f"{existing_note}; {note}"
                        else:
                            new_note = note
                        
                        df.iloc[row_idx, df.columns.get_loc('ë¹„ê³ ')] = new_note
        
        return df
    
    def _save_merged_file(self, combined_data: Dict[str, pd.DataFrame], 
                         output_file: str, reference_structure: FileStructure):
        """
        ê²°í•©ëœ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            combined_data: ê²°í•©ëœ ë°ì´í„°
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            reference_structure: ì›ë³¸ íŒŒì¼ êµ¬ì¡°
        """
        try:
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                for sheet_name, df in combined_data.items():
                    df.to_excel(writer, sheet_name=sheet_name, index=False)
                    
                    # ì—´ ë„ˆë¹„ ìë™ ì¡°ì •
                    worksheet = writer.sheets[sheet_name]
                    self._adjust_column_widths(worksheet, df)
            
            print(f"âœ… ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}")
            
        except Exception as e:
            raise Exception(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def _adjust_column_widths(self, worksheet, df: pd.DataFrame):
        """ì—´ ë„ˆë¹„ ìë™ ì¡°ì •"""
        try:
            for column in worksheet.columns:
                max_length = 0
                column_letter = column[0].column_letter
                
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                
                adjusted_width = min(max_length + 2, 50)
                worksheet.column_dimensions[column_letter].width = adjusted_width
        except Exception:
            pass  # ì—´ ë„ˆë¹„ ì¡°ì • ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
    
    def _update_progress(self, progress: float, message: str):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        self.current_progress = progress * 100
        self.current_status = message
        
        if self.ui:
            self.ui.update_progress(self.current_progress, message)
        
        print(f"ğŸ“Š {self.current_progress:.1f}% - {message}")
    
    def _update_status(self, status: str):
        """ìƒíƒœ ì—…ë°ì´íŠ¸"""
        self.current_status = status
        print(f"â„¹ï¸ {status}")
    
    def _handle_error(self, error_message: str):
        """ì˜¤ë¥˜ ì²˜ë¦¬"""
        self.current_status = f"ì˜¤ë¥˜: {error_message}"
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {error_message}")
        
        if self.ui:
            self.ui.show_error(error_message)
    
    def _handle_cancellation(self):
        """ì·¨ì†Œ ì²˜ë¦¬"""
        self.current_status = "ì·¨ì†Œë¨"
        print("â¹ï¸ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        if self.ui:
            self.ui.update_progress(0, "ì·¨ì†Œë¨")
    
    def _show_error(self, message: str):
        """ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ"""
        if self.ui:
            self.ui.show_error(message)
        else:
            print(f"âŒ ì˜¤ë¥˜: {message}")
    
    def _show_success(self, message: str):
        """ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ"""
        if self.ui:
            self.ui.show_success(message)
        else:
            print(f"âœ… ì„±ê³µ: {message}")
    
    def _log_error(self, error_message: str):
        """ì˜¤ë¥˜ ë¡œê·¸ ê¸°ë¡"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {error_message}"
        
        self.change_logs.append(log_entry)
        print(f"âš ï¸ {log_entry}")
        
        # íŒŒì¼ì—ë„ ë¡œê·¸ ì €ì¥
        try:
            with open("merge_errors.log", "a", encoding="utf-8") as f:
                f.write(f"{log_entry}\n")
        except:
            pass
    
    def _create_completion_report(self, processed_files_count: int, 
                                 combined_data: Dict[str, pd.DataFrame],
                                 processing_errors: List[str]):
        """ì™„ë£Œ ë³´ê³ ì„œ ìƒì„±"""
        try:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            report = []
            report.append(f"ğŸ“Š ì—‘ì…€ ì·¨í•© ì™„ë£Œ ë³´ê³ ì„œ")
            report.append(f"ğŸ“… ì™„ë£Œ ì‹œê°„: {timestamp}")
            report.append(f"ğŸ“ ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {processed_files_count}ê°œ")
            report.append(f"ğŸ“‹ ìƒì„±ëœ ì‹œíŠ¸ ìˆ˜: {len(combined_data)}ê°œ")
            report.append("")
            
            # ì‹œíŠ¸ë³„ ìƒì„¸ ì •ë³´
            for sheet_name, df in combined_data.items():
                report.append(f"â€¢ {sheet_name}: {len(df)}í–‰ Ã— {len(df.columns)}ì—´")
            
            if self.change_logs:
                report.append("")
                report.append("âš ï¸ ì²˜ë¦¬ ì¤‘ ë°œìƒí•œ ê²½ê³ /ì˜¤ë¥˜:")
                for log in self.change_logs[-10:]:  # ìµœê·¼ 10ê°œë§Œ
                    report.append(f"  - {log}")
            
            if processing_errors:
                report.append("")
                report.append("âš ï¸ ì²˜ë¦¬ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜:")
                for error in processing_errors[:5]:  # ìµœëŒ€ 5ê°œë§Œ
                    report.append(f"  - {error}")
            
            report_text = "\n".join(report)
            print("\n" + "="*50)
            print(report_text)
            print("="*50)
            
        except Exception as e:
            print(f"âš ï¸ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}") 